<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Dataset | CarlAnomaly Dataset</title>
    <link rel="stylesheet" href="styles.css" />

    <!-- Prism core + chosen theme -->
    <link href="https://cdn.jsdelivr.net/npm/prismjs@1/themes/prism-tomorrow.min.css" rel="stylesheet" />
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-core.min.js" defer></script>

    <!-- Language components (add more as needed) -->
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-python.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-bash.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1/components/prism-json.min.js" defer></script>

</head>

<body>
    <header>
        <div class="header-bar">
            <h1 class="site-title"><a href="index.html">CarlAnomaly</a></h1>

            <nav>
                <ul>
                    <li><a href="index.html">Home</a></li>
                    <li><a href="dataset.html" class="active">Dataset</a></li>
                    <li><a href="download.html">Download</a></li>
                    <li><a href="tasks.html">Tasks</a></li>
                    <li><a href="resources.html">Resources</a></li>
                    <li><a href="about.html">About</a></li>
                </ul>
            </nav>
        </div>
    </header>

    <main>
        <section>
            <h2>Dataset Overview</h2>
            <p><!-- Placeholder: insert composition, modalities, and annotation schema --></p>
        </section>


        <section>
            <h3>Directory Structure</h3>

            <ul class="tree">
                <li>
                    <span class="dir">carlanomaly/</span>
                    <ul>
                        <li>
                            <span class="dir">train/</span>
                            <ul>
                                <li><span class="dir">scenario-1/</span></li>
                                <li><span>...</span></li>

                            </ul>
                        </li>

                        <li>
                            <span class="dir">val/</span>
                            <ul>
                                <li><span class="dir">scenario-1/</span></li>
                                <li><span>...</span></li>

                            </ul>
                        </li>

                        <li>
                            <span class="dir">test/</span>
                            <ul>
                                <ul>
                                    <li><span class="dir">normal/</span></li>
                                    <ul>
                                        <li><span class="dir">scenario-1/</span></li>
                                        <li><span>...</span></li>

                                    </ul>
                                    <li><span class="dir">anomalous/</span></li>
                                    <ul>
                                        <li><span class="dir">scenario-1/</span></li>
                                        <li><span>...</span></li>

                                    </ul>

                                </ul>


                            </ul>
                        </li>

                    </ul>
                </li>

            </ul>
            <br>


        </section>


        <section>



            <h3>Cameras</h3>

            The dataset contains pixel- and instance wise segmentation masks for each object in the scene. Each object
            has a unique ID.
            Since these annotations where generated in a simulation, the annotations are perfect.


            <ul class="tree">
                <li>
                    <span class="dir">scenario/</span>
                    <ul>
                        <li>
                            <span class="dir">rgb-front/</span>
                            <ul>
                                <li><span class="image">000000.jpg</span></li>
                                <li><span>...</span></li>
                            </ul>
                            <span class="dir">segmentation-front/</span>
                            <ul>
                                <li><span class="image">000000.png</span></li>
                                <li><span>...</span></li>
                            </ul>
                            <span class="dir">depth-front/</span>
                            <ul>
                                <li><span class="image">000000.png</span></li>
                                <li><span>...</span></li>
                            </ul>
                            <!-- <li><span class="file">labels.csv</span></li> -->
                    </ul>
                </li>
            </ul>
            <br>

            <pre><code class="language-python">img = Image.open("segmentation-front/000099.png")

# instance ids are encoded in the G and B channel 
id_fields = np.array(img)[:,:,1:3] 
instance_ids = np.zeros(shape=(id_fields.shape[0], id_fields.shape[1]), dtype=np.int32)
instance_ids += id_fields[:,:,0]
instance_ids += id_fields[:,:,1].astype(np.int32) << 8

# per-pixel classes are encoded in the R channel 
segmentation_mask = np.array(img)[:,:,0] 
</code></pre>

            <div class="gallery">
                <figure>
                    <img src="img/000003.jpg" alt="Car Anomaly 1">
                    <figcaption>Camera Image</figcaption>
                </figure>
                <figure>
                    <img src="img/000003.png" alt="Car Anomaly 2">
                    <figcaption>Instance Segmentation Mask</figcaption>
                </figure>
                <figure>
                    <img src="img/000003.png" alt="Car Anomaly 2">
                    <figcaption>Depth Map<figcaption>
                </figure>
            </div>

            <div class="gallery">
                <figure>
                    <img src="img/000080.jpg" alt="Car Anomaly 1">
                    <figcaption>Camera Image</figcaption>
                </figure>

                <figure>
                    <img src="img/000080.png" alt="Car Anomaly 2">
                    <figcaption>Instance Segmentation Mask</figcaption>
                </figure>

                <figure>
                    <img src="img/000080.png" alt="Car Anomaly 2">
                    <figcaption>Depth Map</figcaption>
                </figure>

            </div>

            <section>


                <h3>Semantic LIDAR Point Clouds</h3>
                <p>
                    Pixel-Anotated LIDAR Pointclouds for each frame with realistic settings.
                </p>




                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li>
                                <span class="dir">pointclouds/</span>
                                <ul>
                                    <li><span class="binary">000000.bin</span></li>
                                    <li><span class="binary">labels-000000.bin</span></li>
                                    <li><span>...</span></li>
                                </ul>
                                <!-- <li><span class="file">labels.csv</span></li> -->
                        </ul>
                    </li>
                </ul>
                <br>

                <p>
                    Both points and labels are serialized numpy arrays:



                </p>

                <p>
                <pre><code class="language-python"># x, y, z, and reflectance 
points = np.fromfile("pointclouds/000063.bin", dtype=np.dtype("f4")).reshape(-1, 4)

# class_label and instance_id 
labels = np.fromfile("pointclouds/labels-000063.bin", dtype=np.uint32).reshape(-1, 2)
</code></pre>
                </p>

                <div class="gallery">
                    <figure>
                        <img src="img/pcl-0.jpg" alt="Car Anomaly 1">
                        <figcaption>LIDAR Example 1</figcaption>
                    </figure>
                    <figure>
                        <img src="img/pcl-1.jpg" alt="Car Anomaly 2">
                        <figcaption>LIDAR Example 2</figcaption>
                    </figure>


                </div>

                <h4>KITTI Annotations</h4>
                <p>
                    Kitti annotations contain 3D bounding boxes and connect them to the camera.
                </p>

                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li>
                                <span class="dir">kitti-front/</span>
                                <ul>
                                    <li><span class="dir">complete_data/</span></li>
                                    <ul>
                                        <li><span class="file">000000_extended.json</span></li>
                                        <li><span>...</span></li>
                                    </ul>
                                    <li><span class="dir">label_2/</span></li>
                                    <ul>
                                        <li><span class="file">000000.txt</span></li>
                                        <li><span>...</span></li>
                                    </ul>
                                    <li><span class="dir">calib/</span></li>
                                    <ul>
                                        <li><span class="file">000000.txt</span></li>
                                        <li><span>...</span></li>
                                    </ul>
                                </ul>
                            </li>
                            <!-- <li><span class="file">labels.csv</span></li> -->
                        </ul>
                    </li>
                </ul>

            </section>

            <section>
                <h3>Anomaly Annotations</h3>

                <h4>Sample- and Sensor-Level</h4>

                <p>
                    For <b>cameras</b> the per-pixel anomaly labels are available in a separate directory.
                    Labels are written in a 1-channel PNG where 0 means normal and everything else means anomaly.
                    Sensor-level anomaly labels are given in a CSV with an <code>anomaly</code> column for convenience.
                </p>

                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li>
                                <span class="dir">anomaly-front/</span>
                                <ul>
                                    <li><span class="image">000000.png</span></li>
                                    <li><span>...</span></li>
                                    <li><span class="file">sensor.csv</span></li>
                                </ul>
                        </ul>
                    </li>
                </ul>

                <p>
                    For <b>LiDAR</b> the anomaly labels are similarly available in a separate directory:
                </p>

                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li>
                                <span class="dir">anomaly-pcl/</span>
                                <ul>
                                    <li><span class="binary">000000.bin</span></li>
                                    <li><span>...</span></li>
                                    <li><span class="file">sensor.csv</span></li>
                                </ul>
                        </ul>
                    </li>
                </ul>

                <p>
                    The <code>.bin</code> files are serialized numpy vectors with value 0 if normal and anomaly
                    otherwise.
                </p>



                <h4>Observation-Level</h4>
                In CarlAnomaly, an observation is an anomaly when there is an anomaly in any of the sensors.
                For convenience, these are also stored in CSV:
                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li>
                                <span class="file">anomaly-observation.csv</span>
                        </ul>
                    </li>
                </ul>

                <h4>Scenario-Level</h4>
                These labels are given by the directory.

            </section>


            <section>


                <h3>Additional Sensors</h3>
                The dataset additionally contains sensor readings for the following sensors in CSV format:

                <ul>
                    <li><b>IMU</b>: Measuring acceleration and orientation of the ego vehicle</li>
                    <li><b>GNSS</b>: Measuring position of the vehicle</li>
                    <li><b>Weather</b>: Exact weather conditions</li>
                </ul>



                <ul class="tree">
                    <li>
                        <span class="dir">scenario/</span>
                        <ul>
                            <li><span class="file">gnss.csv</span></li>
                            <li><span class="file">imu.csv</span></li>
                            <li><span class="file">weather.csv</span></li>
                        </ul>
                    </li>
                </ul>

                You can simply load these as pandas dataframes:
                <pre><code class="language-python">import pandas as pd 
weather = pd.read_csv("weather.csv")</code></pre>


                <h4>Example: IMU</h3>
                    The per-step IMU readings look as follows:

                    <div class="table-wrapper">
                        <table class="cool-table">
                            <tr>
                                <th>index</th>
                                <th>acceleration_x</th>
                                <th>acceleration_y</th>
                                <th>acceleration_z</th>
                                <th>compass</th>
                                <th>longitude_x</th>
                                <th>longitude_y</th>
                                <th>longitude_z</th>
                            </tr>
                            <tr>
                                <td>0</td>
                                <td>-1.31</td>
                                <td>0.00</td>
                                <td>9.73</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>-0.02</td>
                                <td>-0.01</td>
                            </tr>
                            <tr>
                                <td>1</td>
                                <td>5.58</td>
                                <td>-0.02</td>
                                <td>9.82</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>-0.01</td>
                                <td>-0.00</td>
                            </tr>
                            <tr>
                                <td>2</td>
                                <td>5.90</td>
                                <td>-0.00</td>
                                <td>9.82</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>-0.01</td>
                                <td>-0.00</td>
                            </tr>
                            <tr>
                                <td>3</td>
                                <td>6.19</td>
                                <td>-0.01</td>
                                <td>9.82</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>-0.00</td>
                                <td>-0.00</td>
                            </tr>
                            <tr>
                                <td>4</td>
                                <td>5.90</td>
                                <td>-0.01</td>
                                <td>9.81</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>-0.00</td>
                                <td>-0.00</td>
                            </tr>
                            <tr>
                                <td>5</td>
                                <td>4.71</td>
                                <td>-0.01</td>
                                <td>9.81</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>0.00</td>
                                <td>-0.00</td>
                            </tr>
                            <tr>
                                <td>6</td>
                                <td>-0.01</td>
                                <td>-0.10</td>
                                <td>9.82</td>
                                <td>3.16</td>
                                <td>-0.00</td>
                                <td>0.01</td>
                                <td>-0.01</td>
                            </tr>
                        </table>
                    </div>


                    <h4>Example: Global Position (GNSS)</h4>


                    <div class="gallery" style="width: 500px; margin: auto;">
                        <figure>
                            <img src="img/gnss.webp" alt="GNSS">
                            <figcaption>GNSS Coordinates in Matplotlib</figcaption>
                        </figure>
                    </div>

            </section>


    </main>

    <footer>
        <p>&copy; 2025 CarlAnomaly Dataset</p>
    </footer>
</body>

</html>